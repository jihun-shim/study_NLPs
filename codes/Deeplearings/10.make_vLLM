{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.40.1 bitsandbytes==0.43.1 accelerate==0.29.3 datasets==2.19.0 tiktoken==0.6.0 -qqq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:46:14.629793Z","iopub.execute_input":"2025-02-10T01:46:14.630198Z","iopub.status.idle":"2025-02-10T01:46:34.158624Z","shell.execute_reply.started":"2025-02-10T01:46:14.630156Z","shell.execute_reply":"2025-02-10T01:46:34.157467Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.12.0 requires pyarrow<19.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 19.0.0 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.3.1 which is incompatible.\nsentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:46:34.160001Z","iopub.execute_input":"2025-02-10T01:46:34.160286Z","iopub.status.idle":"2025-02-10T01:46:34.164213Z","shell.execute_reply.started":"2025-02-10T01:46:34.160249Z","shell.execute_reply":"2025-02-10T01:46:34.163397Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 기존 모델 활용","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM # LLM 모델 loading\n\ntokenizer = AutoTokenizer.from_pretrained(\"beomi/Yi-Ko-6B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"beomi/Yi-Ko-6B\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:46:34.166055Z","iopub.execute_input":"2025-02-10T01:46:34.166262Z","iopub.status.idle":"2025-02-10T01:52:29.246500Z","shell.execute_reply.started":"2025-02-10T01:46:34.166244Z","shell.execute_reply":"2025-02-10T01:52:29.245501Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/9.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71709084be954636977cb02ad612ebea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa0a57332d774eb8ab2fb2ead4e7c8c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/573 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67987e5b8c414fa2b9ca749262118e93"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b04ede7b3d6d4f1e87f2c5dbd0730c85"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb2787805ce4dfea269b7d4d6edee2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4637e2bf5f2451bb19a901eabecf689"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/2.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c4929a4638c41848fef82a1a0657fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/2.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbbaa0cb78a0489698a654bb4a177856"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"920548ebe7944b26a771c85bb423c71f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/2.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee65b9ba85284cb88ef92c9308892bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/643M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b2b163f13e4160993e9be8a4054560"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ae54a3c9c4480190e746d53dffa269"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dca9deac266347009dd3b766581381c4"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"DDL = 'CREATE TABLE players ( player_id INT PRIMARY KEY AUTO_INCREMENT, username VARCHAR(255) UNIQUE NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, password_hash VARCHAR(255) NOT NULL, date_joined DATETIME NOT NULL, last_login DATETIME );'\nQuestion = '모든 플레이어 정보를 조회해 줘'\nSQL = ''\nexample = f'''\n    당신은 sql 생성하는 전문가야.\n    DDL 활용해 Question 해결하는 SQL query 생성\n    추측 과정은 빼고 SQL만 출력\n    {DDL}\n    {Question}\n    {SQL}\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:52:29.248215Z","iopub.execute_input":"2025-02-10T01:52:29.248759Z","iopub.status.idle":"2025-02-10T01:52:29.254827Z","shell.execute_reply.started":"2025-02-10T01:52:29.248722Z","shell.execute_reply":"2025-02-10T01:52:29.253933Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:52:29.255527Z","iopub.execute_input":"2025-02-10T01:52:29.255804Z","iopub.status.idle":"2025-02-10T01:52:29.269684Z","shell.execute_reply.started":"2025-02-10T01:52:29.255783Z","shell.execute_reply":"2025-02-10T01:52:29.268815Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"## 토크나이징\ninputs = tokenizer.encode(example, return_tensors='pt')\nlen(inputs[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:52:29.270469Z","iopub.execute_input":"2025-02-10T01:52:29.270780Z","iopub.status.idle":"2025-02-10T01:52:29.305584Z","shell.execute_reply.started":"2025-02-10T01:52:29.270759Z","shell.execute_reply":"2025-02-10T01:52:29.304898Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"131"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# 모델 예측 수행(생성 글 작성)\noutputs = model.generate(inputs\n              , max_new_tokens=100\n              , pad_token_id = tokenizer.eos_token_id\n              , temperature = 0.5)\n\noutputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:52:29.306375Z","iopub.execute_input":"2025-02-10T01:52:29.306629Z","iopub.status.idle":"2025-02-10T01:54:26.353179Z","shell.execute_reply.started":"2025-02-10T01:52:29.306601Z","shell.execute_reply":"2025-02-10T01:54:26.352092Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"tensor([[    1, 59568,   144,   139, 76851, 71613, 33162, 64069, 76858, 64018,\n         65475, 76848,    98,   144,   139, 14499, 59620, 69033, 24983, 65192,\n         64018, 16292,  8975, 64069, 76858,   144,   139, 76992, 77248, 64230,\n         65028, 67533, 16292, 76822, 64179, 76963,   144,   139, 57739, 30589,\n          3411,   662,  3875, 59593,   619, 11710,  6123,  3811, 15914, 34341,\n         58552, 59593,  1625, 26406, 12766,    97, 20576,  1008, 23778,  1955,\n         59605,    79,    82,    82, 59604,  8568, 59597, 24849,  5928,  8987,\n            97,  3449,  1008, 23778,  1955, 59605,    79,    82,    82, 59604,\n          8568, 59597, 24849,  5928,  8987,    97,  8355, 59593, 14529,  1008,\n         23778,  1955, 59605,    79,    82,    82, 59604,  5928,  8987,    97,\n          3817, 59593,  9522,  1559,   723,  1765,  3013, 13862,  5928,  8987,\n            97,  1426, 59593, 17817,   723,  1765,  3013, 13862, 58946,   144,\n           139, 71386, 67763, 76816, 68724, 72178, 63934, 69305,   144,   139,\n           144,   139, 27683,  1307, 17509,  3411, 59631,   144,   139, 71386,\n         67763, 76816, 68724, 72178, 63934, 69305,   144,   139,   144,   139,\n         27683,  1307, 17509,  3411, 31686, 20576,   762,  1111, 59617,  1577,\n         32958,   144,   139, 59610, 59617,  1577, 59610, 64291, 76607, 68724,\n         72178, 63934, 69305,   144,   139,   144,   139, 27683,  1307, 17509,\n          3411, 31686, 20576,   762,  1111, 59617,  1577, 59610,  6101,  8355,\n         59593, 14529,   762,  1111,    78,    79,    80,    81,    82,    83,\n            84,    85, 32958,   144,   139, 59610, 59617,  1577, 59610, 64291,\n         76607, 68724, 72178, 63934, 69305,  6101,  1111,    78,    79,    80,\n            81,    82,    83,    84,    85, 59610, 64628, 73357, 77098, 66287,\n         66040]])"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# 생성된 텍스트 출력\nresult = tokenizer.decode(outputs[0], skip_special_tokens = True)\nresult","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:54:26.355044Z","iopub.execute_input":"2025-02-10T01:54:26.355312Z","iopub.status.idle":"2025-02-10T01:54:26.361989Z","shell.execute_reply.started":"2025-02-10T01:54:26.355288Z","shell.execute_reply":"2025-02-10T01:54:26.361351Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\" \\n    당신은 sql 생성하는 전문가야.\\n    DDL 활용해 Question 해결하는 SQL query 생성\\n    추측 과정은 빼고 SQL만 출력\\n    CREATE TABLE players ( player_id INT PRIMARY KEY AUTO_INCREMENT, username VARCHAR(255) UNIQUE NOT NULL, email VARCHAR(255) UNIQUE NOT NULL, password_hash VARCHAR(255) NOT NULL, date_joined DATETIME NOT NULL, last_login DATETIME );\\n    모든 플레이어 정보를 조회해 줘\\n    \\n    SELECT * FROM players;\\n    모든 플레이어 정보를 조회해 줘\\n    \\n    SELECT * FROM players WHERE username = 'james';\\n    'james'라는 사용자 정보를 조회해 줘\\n    \\n    SELECT * FROM players WHERE username = 'james' AND password_hash = '12345678';\\n    'james'라는 사용자 정보를 조회해 줘 AND '12345678'이라는 패스워드를 가진\""},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"### 모델을 한번에 동작 하게 작성","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig, pipeline\n\ndef make_inference_pipeline(model_id):\n    # 토크나이징 \n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n\n    # 모델\n    model = AutoModelForCausalLM.from_pretrained(model_id\n                                                , load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16 # 양자화 정의\n                                                , device_map='auto')\n    \n    # pipline : 예측 초기화 설정\n    pipe = pipeline('text-generation',model=model, tokenizer=tokenizer)\n    return pipe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T01:54:26.363015Z","iopub.execute_input":"2025-02-10T01:54:26.363294Z","iopub.status.idle":"2025-02-10T01:54:37.622323Z","shell.execute_reply.started":"2025-02-10T01:54:26.363265Z","shell.execute_reply":"2025-02-10T01:54:37.621670Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model_id = \"beomi/Yi-Ko-6B\"\nhf_pipe = make_inference_pipeline(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T02:04:27.026589Z","iopub.execute_input":"2025-02-10T02:04:27.026947Z","iopub.status.idle":"2025-02-10T02:05:18.044438Z","shell.execute_reply.started":"2025-02-10T02:04:27.026921Z","shell.execute_reply":"2025-02-10T02:05:18.043709Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nThe `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a5f91b2d8a45eea0fa906bf181e4aa"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"results = hf_pipe(example, do_sample=False\n       , return_full_text=False, max_length=512, truncation=True)\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T02:12:31.386119Z","iopub.execute_input":"2025-02-10T02:12:31.386479Z","iopub.status.idle":"2025-02-10T02:12:58.329172Z","shell.execute_reply.started":"2025-02-10T02:12:31.386451Z","shell.execute_reply":"2025-02-10T02:12:58.328333Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"    SELECT * FROM players;\\n    \\n    SELECT * FROM players WHERE username = 'jonghoon';\\n    \\n    SELECT * FROM players WHERE email = 'jonghoon@gmail.com';\\n    \\n    SELECT * FROM players WHERE password_hash = '123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234\"}]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"type(hf_pipe), type(pipeline)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T02:13:00.868206Z","iopub.execute_input":"2025-02-10T02:13:00.868497Z","iopub.status.idle":"2025-02-10T02:13:00.873916Z","shell.execute_reply.started":"2025-02-10T02:13:00.868474Z","shell.execute_reply":"2025-02-10T02:13:00.873148Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(transformers.pipelines.text_generation.TextGenerationPipeline, function)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"type(results), type(results[0]), results[0].keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T02:14:33.783163Z","iopub.execute_input":"2025-02-10T02:14:33.783463Z","iopub.status.idle":"2025-02-10T02:14:33.789318Z","shell.execute_reply.started":"2025-02-10T02:14:33.783441Z","shell.execute_reply":"2025-02-10T02:14:33.788580Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(list, dict, dict_keys(['generated_text']))"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"results[0]['generated_text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-10T02:14:56.677803Z","iopub.execute_input":"2025-02-10T02:14:56.678082Z","iopub.status.idle":"2025-02-10T02:14:56.683127Z","shell.execute_reply.started":"2025-02-10T02:14:56.678062Z","shell.execute_reply":"2025-02-10T02:14:56.682441Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"\"    SELECT * FROM players;\\n    \\n    SELECT * FROM players WHERE username = 'jonghoon';\\n    \\n    SELECT * FROM players WHERE email = 'jonghoon@gmail.com';\\n    \\n    SELECT * FROM players WHERE password_hash = '123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234\""},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}